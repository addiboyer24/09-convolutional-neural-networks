{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 9 - Convolutional Neural Networks\n",
    "\n",
    "## Reading (or watching, as the case may be): \n",
    "(Andrew Ng Stanford Lecture)[https://www.youtube.com/watch?v=bNb2fEVKeEo]\n",
    "\n",
    "## IC9A Implement Convolution\n",
    "Implement a function that takes an arbitrary 1D input and an arbitrary 1D kernel, and outputs their convolution.  An easy way to check if your implementation is correct is to apply the kernel \n",
    "$$\n",
    "[-1,0,1]\n",
    "$$\n",
    "to a sine function, and see if it returns (a scaled version of) cosine.  Apply a moving average kernel to the same function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [1 3 5 3 1] convolved with [0.33333333 0.33333333 0.33333333] = [3.         3.66666667 3.        ]\n",
      "x: [1 3 5 3 1] convolved with [0.33333333 0.33333333 0.33333333] = [3.0, 3.6666666666666665, 3.0]\n",
      "Max pooling of [1, 3, 5, 7, 9, 11] with stride 3 = [5, 11]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([1,3,5,3,1])\n",
    "kernel = np.array([1/3,1/3,1/3])\n",
    "\n",
    "def convolution(x, kernel, stride=1):\n",
    "    h = []\n",
    "    for i in range(0, len(x) - len(kernel)+1, stride):\n",
    "        tot = 0\n",
    "        for j in range(len(kernel)):\n",
    "            tot += kernel[j]* x[i+j]\n",
    "        h.append(tot)\n",
    "    \n",
    "    return np.array(h)\n",
    "\n",
    "def convolution_mult(x, kernel, stride=1):\n",
    "    h = []\n",
    "    k_len = len(kernel)\n",
    "    \n",
    "    for i in range(0, len(x) - len(kernel)+1, stride):\n",
    "        h.append(kernel @ x[i:i+k_len])\n",
    "    \n",
    "    return np.array(h)\n",
    "\n",
    "answer = convolution(x, kernel, 1)\n",
    "print('x: {} convolved with {} = {}'.format(x, kernel, answer))\n",
    "\n",
    "answer = convolution_new(x, kernel, 1)\n",
    "print('x: {} convolved with {} = {}'.format(x, kernel, answer))\n",
    "\n",
    "\n",
    "x = [1,3,5,7,9,11]\n",
    "stride = 3\n",
    "def max_pooling(x, stride=1):\n",
    "    h = []\n",
    "    for i in range(0,len(x), stride):\n",
    "        h.append(max(x[i:i+stride]))\n",
    "    return h\n",
    "\n",
    "answer = max_pooling(x, stride)\n",
    "print('Max pooling of {} with stride {} = {}'.format(x, stride, answer))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Implementing a CNN for song classification\n",
    "\n",
    "First of all, we need a dataset.  I've grabbed one from the internet that consists of 100 songs per genre.  We'll limit ourselves to blues, metal, country, and hiphop.  I can use scipy to import .wav files and create a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "genres = ['blues','metal','country','hiphop','jazz','classical']\n",
    "\n",
    "N=len(genres)\n",
    "\n",
    "wavlist = []\n",
    "labels = []\n",
    "\n",
    "# blues=0,metal=1,country=2,hiphop=3\n",
    "for i,genre in enumerate(genres):\n",
    "    files = os.listdir('data/genres/'+genre)\n",
    "    for f in files:\n",
    "        filename = 'data/genres/'+genre+'/'+f\n",
    "        count,data = wavfile.read(filename)\n",
    "        \n",
    "        # Here, I am downsampling the data by a factor of 8, and keeping only the first 65536 features,\n",
    "        # roughly one minute of song\n",
    "        wavlist.append(data[:2**19:8]/2**15)\n",
    "        labels.append(i)\n",
    "       \n",
    "y = np.array(labels)\n",
    "X = np.vstack(wavlist)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot some examples of the wave-forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "import matplotlib.pyplot as plt\n",
    "fig,axs = plt.subplots(nrows=4,ncols=1)\n",
    "fig.set_size_inches(10,10)\n",
    "for ax,index in zip(axs,[0,100,200,300]):\n",
    "    ax.plot(X[index,:])\n",
    "    ax.set_xlim(0,10000)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are definitely differences, but maybe that's just random.  What does a couple examples of metal look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,axs = plt.subplots(nrows=4,ncols=1)\n",
    "fig.set_size_inches(10,10)\n",
    "for ax,index in zip(axs,[300,301,302,303]):\n",
    "    ax.plot(X[index,:])\n",
    "    ax.set_xlim(0,10000)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't know.  We'll see if we can extract some characteristic features.  To do this, we'll learn filters which are then *convolved* over the signal.  \n",
    "\n",
    "Despite having relatively few examples (100 for each genre!), we'll want to ensure that our method can generalize, so let's split our data into test and training sets.  At the same time, we'll want to reshape our arrays into what pytorch expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Training/test set split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=1)\n",
    "\n",
    "X_train = X_train.reshape((*X_train.shape,1))\n",
    "X_test = X_test.reshape((*X_test.shape,1))\n",
    "\n",
    "print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can do our normal ritual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "X_train = torch.from_numpy(X_train)\n",
    "X_test = torch.from_numpy(X_test)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "\n",
    "\n",
    "X_train = X_train.to(torch.float32)\n",
    "\n",
    "#Pytorch expects channels first, so reshape\n",
    "X_train = X_train.reshape(-1,1,2**16)\n",
    "X_test = X_test.to(torch.float32)\n",
    "X_test = X_test.reshape(-1,1,2**16)\n",
    "y_train = y_train.to(torch.long)\n",
    "y_test = y_test.to(torch.long)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "X_train = X_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "y_train = y_train.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "training_data = TensorDataset(X_train,y_train)\n",
    "test_data = TensorDataset(X_test,y_test)\n",
    "\n",
    "batch_size = 50\n",
    "train_loader = torch.utils.data.DataLoader(dataset=training_data,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "batch_size = 50\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can define our model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        This method is where you'll want to instantiate parameters and functions.\n",
    "        Here, we instantiate four 1D convolution layers and four max pooling layers\n",
    "        \"\"\"\n",
    "        super(Net,self).__init__()\n",
    "        # Conv1d arguments: number of input feature maps, number of output feature maps, kernel width, edge padding\n",
    "        self.conv1 = nn.Conv1d(1,10,9,padding=4)\n",
    "        # MaxPool1d arguments: kernel width, edge padding\n",
    "        self.pool1 = nn.MaxPool1d(16,padding=4)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(10,10,9,padding=4)\n",
    "        self.pool2 = nn.MaxPool1d(16,padding=4)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(10,10,9,padding=4)\n",
    "        self.pool3 = nn.MaxPool1d(16,padding=4)\n",
    "        \n",
    "        self.conv4 = nn.Conv1d(10,10,9,padding=4)\n",
    "        self.pool4 = nn.MaxPool1d(16,padding=4)\n",
    "        \n",
    "        self.l1 = nn.Linear(10,128)\n",
    "        self.l2 = nn.Linear(128,6)\n",
    "        \n",
    "        self.dropout_1 = nn.Dropout(p=0.2)\n",
    "        self.dropout_2 = nn.Dropout(p=0.5)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "        This method runs the feedforward neural network.  \n",
    "        \"\"\"\n",
    "        \n",
    "        # Apply convolution\n",
    "        a1 = self.conv1(x)\n",
    "        \n",
    "        # Apply activation function\n",
    "        z1 = torch.relu(a1)\n",
    "        \n",
    "        # Apply max pooling\n",
    "        z1 = self.pool1(z1)\n",
    "                \n",
    "        a2 = self.conv2(z1)\n",
    "        z2 = torch.relu(a2)\n",
    "        z2 = self.pool2(z2)\n",
    "        \n",
    "        a3 = self.conv3(z2)\n",
    "        z3 = torch.relu(a3)\n",
    "        z3 = self.pool3(z3)\n",
    "        \n",
    "        a4 = self.conv4(z3)\n",
    "        z4 = torch.relu(a4)\n",
    "        z4 = self.pool4(z4)        \n",
    "        \n",
    "        # Flatten the array (basically removes singleton dimension)\n",
    "        z_flat = self.dropout_1(torch.reshape(z4,(-1,10)))\n",
    "        \n",
    "        # Apply linear transformation\n",
    "        a5 = self.l1(z_flat)\n",
    "        z5 = self.dropout_2(torch.relu(a5))\n",
    "        \n",
    "        a6 = self.l2(a5)\n",
    "        # Output logits to softmax\n",
    "        return a6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, our training proceeds very much as it has in the past, because our neural network is simply a function from inputs to outputs.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model.to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "\n",
    "epochs = 200\n",
    "# Loop over the data\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    # Loop over each subset of data\n",
    "    for d,t in train_loader:\n",
    "\n",
    "        # Zero out the optimizer's gradient buffer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Make a prediction based on the model\n",
    "        outputs = model(d)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs,t)   \n",
    "\n",
    "        # Use backpropagation to compute the derivative of the loss with respect to the parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Use the derivative information to update the parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "    model.eval()\n",
    "    # After every 10th epoch, compute the test set accuracy\n",
    "    if epoch%10==0:\n",
    "        total=0.\n",
    "        correct=0.\n",
    "        # Loop over all the test examples and accumulate the number of correct results in each batch\n",
    "        for d,t in test_loader:\n",
    "            outputs = model(d)\n",
    "            _, predicted = torch.max(outputs.data,1)\n",
    "            total += float(t.size(0))\n",
    "            correct += float((predicted==t).sum())\n",
    "        total_train = 0\n",
    "        correct_train = 0\n",
    "        for d,t in train_loader:\n",
    "            outputs = model(d)\n",
    "            _, predicted = torch.max(outputs.data,1)\n",
    "            total_train += float(t.size(0))\n",
    "            correct_train += float((predicted==t).sum())\n",
    "        \n",
    "        # Print the epoch, the training loss, and the test set accuracy.\n",
    "        train_accs.append(100.*correct_train/total_train)\n",
    "        test_accs.append(100.*correct/total)\n",
    "\n",
    "        print(epoch,loss.item(),train_accs[-1],test_accs[-1])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are we overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_accs,label='Training accuracy')\n",
    "plt.plot(test_accs,label='Test accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "y_pred = np.argmax(model(X_test).cpu().detach(),axis=1)\n",
    "y_test_cpu = y_test.cpu()\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(genres)\n",
    "cm = confusion_matrix(y_pred,y_test_cpu)\n",
    "precision = np.diag(cm)/cm.sum(axis=1)\n",
    "recall = np.diag(cm)/cm.sum(axis=0)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah, probably.  However, all of our old techniques for regularization can still apply here: $L_2$ regularization, dropout, etc. (data augmentation?) could work, but it's easier to get an intuitive sense for this stuff by looking at images rather than sound files. \n",
    "\n",
    "## 2 Application to images.\n",
    "While very useful for application to 1D sequences like sound, the application that primarily spurred the development of CNNs was in *image processing*.  In particular, CNNs are good at image classification problems, because they have the capacity to scan the entire image and find relevant features no matter where they appear in an image.  For example, if we're trying to tell the difference between cats and hedgehogs, a CNN can detect spines, regardless of where they appears in an image, then aggregate the presence of spines with other evidence in order to compute a class.  \n",
    "\n",
    "How does the convolution operation work in 2D?  Exactly the same as in 1D.  We simply define a 2D kernel, slide it over all possible positions in an image, and compute the inner product between the kernel and the image at its current location.  For example, if we wanted to compute the gradient in the x-direction of an image (because maybe that's useful for detecting spines), we could do the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as ssig\n",
    "\n",
    "hedgehog = plt.imread('images/hedgehog.jpg')\n",
    "hedgehog = hedgehog.mean(axis=2)/255.\n",
    "\n",
    "sobol_x = np.array([[-1,0,1],\n",
    "                    [-2,0,1],\n",
    "                    [-1,0,1]])\n",
    "\n",
    "fmap_sobol_x = ssig.convolve2d(hedgehog,sobol_x,mode='valid')\n",
    "plt.imshow(fmap_sobol_x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNNs learn many kernels, so that at any given convolution layer in a neural network, we might produce multiple feature maps (or bands).  For example, for our grayscale hedgehog image, we might learn filters that compute the x-gradient, y-gradient, and also the Laplacian (curvature).  This would produce a 3-band output image like this one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as ssig\n",
    "\n",
    "def relu(X):\n",
    "    return np.maximum(X,0)\n",
    "\n",
    "def scale(f):\n",
    "    return (f - f.min())/(f.max()-f.min())\n",
    "\n",
    "sobol_x = 1.0*np.array([[-1,0,1],\n",
    "                    [-2,0,1],\n",
    "                    [-1,0,1]])\n",
    "\n",
    "sobol_y = sobol_x.T\n",
    "\n",
    "laplace = 1./8.*np.array([[0,-1,0],\n",
    "                         [-1,4,-1],\n",
    "                         [0,-1,0]])\n",
    "\n",
    "fmap_sobol_x = ssig.convolve2d(hedgehog,sobol_x,mode='valid')\n",
    "fmap_sobol_y = ssig.convolve2d(hedgehog,sobol_y,mode='valid')\n",
    "fmap_laplace = ssig.convolve2d(hedgehog,laplace,mode='valid')\n",
    "\n",
    "y = relu(np.dstack((scale(fmap_sobol_x),scale(fmap_sobol_y),scale(fmap_laplace))))\n",
    "\n",
    "plt.imshow(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying a false color image of the resulting feature maps, we can see that things like the hedghog quills are highlighted.  Perhaps this transformation of the input can help us in determining what this creature is?  There are few other animals which would yield such a pattern.  This is the fundamental utility of the convolutional part of the neural network: to non-linearly transform the inputs into something that is more easily interpreted as the object that it is.  \n",
    "\n",
    "How is this a type of neural network?  In the case of a CNN, the coefficients of the kernels are tunable parameters, or weights.  Thus, if highlighting vertical lines in the image were to help the neural network correctly classify the image as a hedgehog, then perhaps it would learn some approximation to the Sobol-x kernel.  The *architecture* of a CNN typically looks sort of like this:\n",
    "<img src=\"images/cnn.png\" width=800/>\n",
    "We take an input image, and convolve it with a bunch of learned kernels to produce a bunch of feature maps.  Optionally, we will then downsample these feature maps (a popular method is called max-pooling, where we downsample by grabbing the largest value in a region).  This resulting set of feature maps is essentially a new image, and we can repeat the process, convolving with a new set of kernels to achieve yet another feature map, which optionally downscale.  This process is repeated until the image is small enough that we can use its pixels as inputs to a normal multilayer perceptron neural network.  Thus the convolutional part of the neural network can be seen as a form of data reduction, where we sequentially highlight the most salient features of our image, keeping those and throwing away superfluous features until we can make a decision about what we're looking at based on those reduced features.\n",
    "\n",
    "\n",
    "## Implementation of a Image Classifying CNN in pytorch\n",
    "Implementation of a 2D CNN isn't so different from implementation of a 1D CNN in pytorch; really, the only difference is in the dimensionality of the data.  Rather than having data with dimension $m\\times 1\\times n$, we'll now have data with dimention $m\\times 3\\times w \\times h$.  \n",
    "\n",
    "We begin by looking at a new dataset, called CIFAR-10, which contains 60000 3x32x32 images, each of which contains an object in one of 10 classes: airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks.  We seek to develop a neural network that can, given a new input image, successfully classify the image into one of these categories.  CIFAR-10 is a classic and highly standardized benchmark dataset for image recognition algorithms.  The images are also small enough to make for pretty fast and efficient model training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "X_train = torch.from_numpy(np.swapaxes(trainset.data/255.,1,3))\n",
    "X_test = torch.from_numpy(np.swapaxes(testset.data/255.,1,3))\n",
    "y_train = torch.from_numpy(np.array(trainset.targets))\n",
    "y_test = torch.from_numpy(np.array(testset.targets))\n",
    "\n",
    "\n",
    "X_train = X_train.to(torch.float32)\n",
    "X_test = X_test.to(torch.float32)\n",
    "y_train = y_train.to(torch.long)\n",
    "y_test = y_test.to(torch.long)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "X_train = X_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "y_train = y_train.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "training_data = TensorDataset(X_train,y_train)\n",
    "test_data = TensorDataset(X_test,y_test)\n",
    "\n",
    "batch_size = 256\n",
    "train_loader = torch.utils.data.DataLoader(dataset=training_data,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "batch_size = 256\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot a few of these images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(nrows=3,ncols=5,figsize=(12,8))\n",
    "axs = axs.ravel()\n",
    "\n",
    "print(classes)\n",
    "\n",
    "for ax in axs:\n",
    "    idx = np.random.randint(0,50000)\n",
    "    ax.imshow(trainset.data[idx])\n",
    "    ax.set_title(classes[trainset.targets[idx]])\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is clearly a much harder dataset than MNIST!  For reference, human accuracy on this dataset is around 94%.  State of the art CNNs can reach 99%.  This is fairly interesting, in that machine performance on this dataset is *substantially* better than human performance.\n",
    "\n",
    "Let's consider the CNN architecture that we'd like to use.  The opportunities are endless, and the dataset is large enough to warrant something reasonably complex.  I've selected a relatively arbitrary network architecture that consists of 1) a series of convolutions that transforms the input from 3x32x32 to 256x4x4, 2) a flattening of the network into a vector of length 4096, 3) a standard multilayer perceptron that takes 4096 inputs and produces 10 logit scores, one for each class.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"An implementation of a CNN for CIFAR-10\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"CNN Builder.\"\"\"\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv_layer = nn.Sequential(\n",
    "\n",
    "            # Conv Layer block 1\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Conv Layer block 2\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Conv Layer block 3\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(4096, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Perform forward.\"\"\"\n",
    "        \n",
    "        # conv layers\n",
    "        x = self.conv_layer(x)\n",
    "        \n",
    "        # flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # fc layer\n",
    "        x = self.fc_layer(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can print a nice summary (if you have the torchsummary python package) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "model = Net()\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "summary(model,(3,32,32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.8M parameters!  This is a pretty big model!  Nonetheless, we can train it on the GPU in a pretty reasonable amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "\n",
    "epochs = 20\n",
    "# Loop over the data\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    # Loop over each subset of data\n",
    "    for d,t in train_loader:\n",
    "\n",
    "        # Zero out the optimizer's gradient buffer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Make a prediction based on the model\n",
    "        outputs = model(d)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs,t)   \n",
    "\n",
    "        # Use backpropagation to compute the derivative of the loss with respect to the parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Use the derivative information to update the parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(epoch,loss.item())\n",
    "\n",
    "model.eval()\n",
    "total=0.\n",
    "correct=0.\n",
    "# Loop over all the test examples and accumulate the number of correct results in each batch\n",
    "for d,t in test_loader:\n",
    "    outputs = model(d)\n",
    "    _, predicted = torch.max(outputs.data,1)\n",
    "    total += float(t.size(0))\n",
    "    correct += float((predicted==t).sum())\n",
    "total_train = 0\n",
    "correct_train = 0\n",
    "for d,t in train_loader:\n",
    "    outputs = model(d)\n",
    "    _, predicted = torch.max(outputs.data,1)\n",
    "    total_train += float(t.size(0))\n",
    "    correct_train += float((predicted==t).sum())\n",
    "        \n",
    "# Print the epoch, the training loss, and the test set accuracy.\n",
    "train_accs.append(100.*correct_train/total_train)\n",
    "test_accs.append(100.*correct/total)\n",
    "print(train_accs[-1],test_accs[-1])\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "93% training set accuracy, 78% test set accuracy.  If we were to allow this network to continue training, we might do a little better, but we're already seeing signs of overfitting.  **How might we avoid overfitting in this dataset?**.  \n",
    "\n",
    "## IC9B Evaluating the model\n",
    "Create a confusion matrix for the test set.  What classes seem to be getting confused for others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following file if you'd like to load the pre-trained model, rather than train it yourself.\n",
    "# This is the preferred mechanism if you're not using a GPU, as the above model could take a long time to train. \n",
    "#model = torch.load('model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IC9C Looking at learned kernels\n",
    "We can gain a little bit of insight into what features our neural network has learned to extract by looking directly at the kernels that we've learned, just as we did with the weights in previous examples.  You can access the parameters of the model (sequentially ordered) by using the same construct that we used in previous examples to get the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [p for p in model.parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot each kernel in the first convolutional layer** (this will be the first element in params, and there will be 32 of them).  Note that, because the image has 3 bands, these kernels are 3x3x3: you'll want to visualize them as color images.  It can be a little bit of a challenge to understand the effect of a 3x3x3 kernel just by looking at it: **convolve a few of these kernels with an image of your choice (maybe one you grab from CIFAR-10 is easiest), and see what the resulting feature maps look like.  Can you identify what features a kernel is activating on?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.6.8"
=======
   "version": "3.7.3"
>>>>>>> upstream/master
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
